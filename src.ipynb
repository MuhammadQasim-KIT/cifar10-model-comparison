{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "743bb604",
   "metadata": {},
   "source": [
    "# CIFAR-10 Model Comparison (Custom CNN vs ResNet50 vs VGG16 vs DenseNet121)\n",
    "This notebook trains four models on **CIFAR-10**, stores them in memory, saves checkpoints, and **visualizes predictions** on the *same sample test images* for each model.\n",
    "\n",
    "**What you get:**\n",
    "- Trained models accessible via `trained_models[...]`\n",
    "- Saved weights in `checkpoints/`\n",
    "- Accuracy curves\n",
    "- Prediction grids (GT vs Pred + confidence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1927725",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b467e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a568e3",
   "metadata": {},
   "source": [
    "## 2. Dataset & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e53d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "testset  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(trainset), \"| Test size:\", len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8139f56",
   "metadata": {},
   "source": [
    "## 3. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,  6, 5)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "        # CIFAR-10 32x32 -> after conv/pool:\n",
    "        # 32 -> conv5 => 28 -> pool => 14\n",
    "        # 14 -> conv5 => 10 -> pool => 5\n",
    "        # channels=16 => 16*5*5 = 400\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def build_resnet50(num_classes=10):\n",
    "    weights = models.ResNet50_Weights.DEFAULT\n",
    "    model = models.resnet50(weights=weights)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def build_vgg16(num_classes=10):\n",
    "    weights = models.VGG16_Weights.DEFAULT\n",
    "    model = models.vgg16(weights=weights)\n",
    "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def build_densenet121(num_classes=10):\n",
    "    weights = models.DenseNet121_Weights.DEFAULT\n",
    "    model = models.densenet121(weights=weights)\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc25195e",
   "metadata": {},
   "source": [
    "## 4. Training & Evaluation Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ced48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def fit_model(model, model_name, trainloader, testloader, device, epochs=5, lr=0.001, momentum=0.9):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
    "\n",
    "    best_acc = -1.0\n",
    "    best_state = None\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        t0 = time.time()\n",
    "\n",
    "        tr_loss, tr_acc = train_one_epoch(model, trainloader, criterion, optimizer, device)\n",
    "        te_loss, te_acc = evaluate(model, testloader, criterion, device)\n",
    "\n",
    "        history[\"train_loss\"].append(tr_loss)\n",
    "        history[\"train_acc\"].append(tr_acc)\n",
    "        history[\"test_loss\"].append(te_loss)\n",
    "        history[\"test_acc\"].append(te_acc)\n",
    "\n",
    "        if te_acc > best_acc:\n",
    "            best_acc = te_acc\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = epoch\n",
    "\n",
    "        dt = time.time() - t0\n",
    "        print(f\"[{model_name}] Epoch {epoch:02d}/{epochs} | \"\n",
    "              f\"Train: loss={tr_loss:.4f}, acc={tr_acc:.4f} | \"\n",
    "              f\"Test: loss={te_loss:.4f}, acc={te_acc:.4f} | \"\n",
    "              f\"{dt:.1f}s\")\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, history, best_acc, best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933cf75",
   "metadata": {},
   "source": [
    "## 5. Visualization Utilities (Predictions on Sample Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c3c450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _denorm(img_tensor):\n",
    "    # inverse Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "    return img_tensor * 0.5 + 0.5\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_model_predictions(model, model_name, testloader, device, n_images=8, fixed_batch=None):\n",
    "    model.eval()\n",
    "\n",
    "    if fixed_batch is None:\n",
    "        images, labels = next(iter(testloader))\n",
    "    else:\n",
    "        images, labels = fixed_batch\n",
    "\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    outputs = model(images)\n",
    "    probs = F.softmax(outputs, dim=1)\n",
    "    confs, preds = torch.max(probs, 1)\n",
    "\n",
    "    images_vis = _denorm(images.detach().cpu()).clamp(0, 1).numpy()\n",
    "\n",
    "    cols = 4\n",
    "    rows = int(np.ceil(n_images / cols))\n",
    "    plt.figure(figsize=(cols * 4, rows * 4))\n",
    "\n",
    "    for i in range(min(n_images, images_vis.shape[0])):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(np.transpose(images_vis[i], (1, 2, 0)))\n",
    "        gt = classes[labels[i].item()]\n",
    "        pr = classes[preds[i].item()]\n",
    "        cf = confs[i].item()\n",
    "        plt.title(f\"GT: {gt}\\nPred: {pr} ({cf:.2f})\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(model_name, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf77d29",
   "metadata": {},
   "source": [
    "## 6. Train All Models (Store + Save + Visualize)\n",
    "This section:\n",
    "- Trains each model\n",
    "- Stores it in `trained_models`\n",
    "- Saves weights in `checkpoints/`\n",
    "- Visualizes predictions on the **same** sample batch for fair comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd8f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LR = 0.001\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "trained_models = {}\n",
    "histories = {}\n",
    "summary = []\n",
    "\n",
    "# Use the SAME images for all models in visualization (fair comparison)\n",
    "fixed_images, fixed_labels = next(iter(testloader))\n",
    "fixed_batch = (fixed_images, fixed_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ff3f99",
   "metadata": {},
   "source": [
    "### 6.1 Train Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e81d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Custom CNN\"\n",
    "model = CustomCNN(num_classes=10)\n",
    "\n",
    "model, history, best_acc, best_epoch = fit_model(\n",
    "    model, model_name, trainloader, testloader, device,\n",
    "    epochs=EPOCHS, lr=LR, momentum=MOMENTUM\n",
    ")\n",
    "\n",
    "trained_models[model_name] = model\n",
    "histories[model_name] = history\n",
    "torch.save(model.state_dict(), \"checkpoints/custom_cnn_cifar10.pth\")\n",
    "\n",
    "summary.append([model_name, best_acc, best_epoch])\n",
    "visualize_model_predictions(model, model_name, testloader, device, n_images=8, fixed_batch=fixed_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4fb94",
   "metadata": {},
   "source": [
    "### 6.2 Train ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f85952",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ResNet50\"\n",
    "model = build_resnet50(num_classes=10)\n",
    "\n",
    "model, history, best_acc, best_epoch = fit_model(\n",
    "    model, model_name, trainloader, testloader, device,\n",
    "    epochs=EPOCHS, lr=LR, momentum=MOMENTUM\n",
    ")\n",
    "\n",
    "trained_models[model_name] = model\n",
    "histories[model_name] = history\n",
    "torch.save(model.state_dict(), \"checkpoints/resnet50_cifar10.pth\")\n",
    "\n",
    "summary.append([model_name, best_acc, best_epoch])\n",
    "visualize_model_predictions(model, model_name, testloader, device, n_images=8, fixed_batch=fixed_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427036cf",
   "metadata": {},
   "source": [
    "### 6.3 Train VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556cacad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"VGG16\"\n",
    "model = build_vgg16(num_classes=10)\n",
    "\n",
    "model, history, best_acc, best_epoch = fit_model(\n",
    "    model, model_name, trainloader, testloader, device,\n",
    "    epochs=EPOCHS, lr=LR, momentum=MOMENTUM\n",
    ")\n",
    "\n",
    "trained_models[model_name] = model\n",
    "histories[model_name] = history\n",
    "torch.save(model.state_dict(), \"checkpoints/vgg16_cifar10.pth\")\n",
    "\n",
    "summary.append([model_name, best_acc, best_epoch])\n",
    "visualize_model_predictions(model, model_name, testloader, device, n_images=8, fixed_batch=fixed_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab39404",
   "metadata": {},
   "source": [
    "### 6.4 Train DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"DenseNet121\"\n",
    "model = build_densenet121(num_classes=10)\n",
    "\n",
    "model, history, best_acc, best_epoch = fit_model(\n",
    "    model, model_name, trainloader, testloader, device,\n",
    "    epochs=EPOCHS, lr=LR, momentum=MOMENTUM\n",
    ")\n",
    "\n",
    "trained_models[model_name] = model\n",
    "histories[model_name] = history\n",
    "torch.save(model.state_dict(), \"checkpoints/densenet121_cifar10.pth\")\n",
    "\n",
    "summary.append([model_name, best_acc, best_epoch])\n",
    "visualize_model_predictions(model, model_name, testloader, device, n_images=8, fixed_batch=fixed_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a93a78",
   "metadata": {},
   "source": [
    "## 7. Plot Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c20f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for name, h in histories.items():\n",
    "    plt.plot(range(1, EPOCHS + 1), h[\"test_acc\"], marker=\"o\", label=name)\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Model Comparison on CIFAR-10 (Test Accuracy)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6448ac3",
   "metadata": {},
   "source": [
    "## 8. Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9245f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(summary, columns=[\"Model\", \"Best Test Acc\", \"Best Epoch\"])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
